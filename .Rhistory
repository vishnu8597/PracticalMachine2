Training   <-training.df[,-c(1:7)]
Test   <-testing[,-c(1:7)]
Training   <-training.df[,-c(1:7)]
Test   <-testing[,-c(1:7)]
Training   <-training[,-c(1:7)]
Test   <-testing[,-c(1:7)]
library(caret)
training<-read.csv('C:/Users/Vishn/Desktop/project ds/data/pml-training.csv', na.strings=c("NA","#DIV/0!",""))
testing <-read.csv('C:/Users/Vishn/Desktop/project ds/data/pml-testing.csv', na.strings=c("NA","#DIV/0!",""))
dim(training)
dim(testing)
Training   <-training[,-c(1:7)]
Test   <-testing[,-c(1:7)]
trainFinal <- trainCleaned[Split, ]
testFinal <- trainCleaned[-Split, ]
trainFinal <- Training[Split, ]
testFinal <- Train[-Split, ]
Split <- createDataPartition(trainCleaned$classe, p=0.70, list=F)
library(rpart)
library(rpart.plot)
library(randomForest)
library(corrplot)
Split <- createDataPartition(trainCleaned$classe, p=0.70, list=F)
library(caret)
install.packages("ggplot2")
library(caret)
install.packages("vctrs")
library(caret)
install.packages("recipes")
library(caret)
training<-read.csv('C:/Users/Vishn/Desktop/project ds/data/pml-training.csv', na.strings=c("NA","#DIV/0!",""))
testing <-read.csv('C:/Users/Vishn/Desktop/project ds/data/pml-testing.csv', na.strings=c("NA","#DIV/0!",""))
dim(training)
dim(testing)
Training   <-training[,-c(1:7)]
Test   <-testing[,-c(1:7)]
Split <- createDataPartition(trainCleaned$classe, p=0.70, list=F)
Split <- createDataPartition(Training$classe, p=0.70, list=F)
trainFinal <- Training[Split, ]
testFinal <- Test[-Split, ]
modelRf <- train(trainFinal$classe ~ ., data=trainFinal, method="rf", trControl=trainControl(method="cv", 5), ntree=250)
classe<-trainFinal$classe
modelRf <- train(classe ~ ., data=trainFinal, method="rf", trControl=trainControl(method="cv", 5), ntree=250)
training <- training[, colSums(is.na(trainRaw)) == 0]
testing <- testing[, colSums(is.na(testRaw)) == 0]
training <- training[, colSums(is.na(training)) == 0]
testing <- testing[, colSums(is.na(testing)) == 0]
modelRf <- train(classe ~ ., data=trainFinal, method="rf", trControl=trainControl(method="cv", 5), ntree=250)
library(caret)
training<-read.csv('C:/Users/Vishn/Desktop/project ds/data/pml-training.csv', na.strings=c("NA","#DIV/0!",""))
testing <-read.csv('C:/Users/Vishn/Desktop/project ds/data/pml-testing.csv', na.strings=c("NA","#DIV/0!",""))
dim(training)
dim(testing)
Training   <-training[,-c(1:7)]
Test   <-testing[,-c(1:7)]
Split <- createDataPartition(Training$classe, p=0.70, list=F)
trainFinal <- Training[Split, ]
testFinal <- Test[-Split, ]
fit <- train(trainFinal$classe ~ ., method = "rf", data = trainFinal)
training1     <-training[,colSums(is.na(training)) == 0]
library(caret)
training<-read.csv('C:/Users/Vishn/Desktop/project ds/data/pml-training.csv', na.strings=c("NA","#DIV/0!",""))
training1     <-training[,colSums(is.na(training)) == 0]
testing <-read.csv('C:/Users/Vishn/Desktop/project ds/data/pml-testing.csv', na.strings=c("NA","#DIV/0!",""))
dim(training)
dim(testing)
Training   <-training1[,-c(1:7)]
Test   <-testing[,-c(1:7)]
Split <- createDataPartition(Training$classe, p=0.70, list=F)
trainFinal <- Training[Split, ]
testFinal <- Test[-Split, ]
classe<-trainFinal$classe
fit <- train(trainFinal$classe ~ ., method = "rf", data = trainFinal)
library(randomForest)
fit <- train(trainFinal$classe ~ ., method = "rf", data = trainFinal)
install.packages("e1071")
library(randomForest)
fit <- train(trainFinal$classe ~ ., method = "rf", data = trainFinal)
library(caret)
library(randomForest)
training<-read.csv('C:/Users/Vishn/Desktop/project ds/data/pml-training.csv', na.strings=c("NA","#DIV/0!",""))
training1     <-training[,colSums(is.na(training)) == 0]
testing <-read.csv('C:/Users/Vishn/Desktop/project ds/data/pml-testing.csv', na.strings=c("NA","#DIV/0!",""))
dim(training)
dim(testing)
Training   <-training1[,-c(1:7)]
Test   <-testing[,-c(1:7)]
Split <- createDataPartition(Training$classe, p=0.70, list=F)
trainFinal <- Training[Split, ]
testFinal <- Test[-Split, ]
classe<-trainFinal$classe
fit <- train(trainFinal$classe ~ ., method = "rf", data = trainFinal)
library(caret)
library(randomForest)
training<-read.csv('C:/Users/Vishn/Desktop/project ds/data/pml-training.csv', na.strings=c("NA","#DIV/0!",""))
training1     <-training[,colSums(is.na(training)) == 0]
testing <-read.csv('C:/Users/Vishn/Desktop/project ds/data/pml-testing.csv', na.strings=c("NA","#DIV/0!",""))
dim(training)
dim(testing)
Training   <-training1[,-c(1:7)]
Test   <-testing[,-c(1:7)]
Split <- createDataPartition(Training$classe, p=0.70, list=F)
trainFinal <- Training[Split, ]
testFinal <- Test[-Split, ]
classe<-trainFinal$classe
model <- "modelFit.RData"
if (!file.exists(model)) {
# If not, set up the parallel clusters.
require(parallel)
require(doParallel)
cl <- makeCluster(detectCores() - 1)
registerDoParallel(cl)
fit <- train(trainFinal$classe ~ ., method = "rf", data = trainFinal)
save(fit, file = "modelFit.RData")
stopCluster(cl)
} else {
# Good model exists from previous run, load it and use it.
load(file = "modelFit.RData", verbose = TRUE)
}
library(parallel)
library(doParallel)
install.packages("doParallel")
library(parallel)
library(doParallel)
install.packages("foreach")
library(parallel)
library(doParallel)
library(foreach)
library(parallel)
library(doParallel)
library(caret)
library(randomForest)
library(foreach)
library(parallel)
library(doParallel)
training<-read.csv('C:/Users/Vishn/Desktop/project ds/data/pml-training.csv', na.strings=c("NA","#DIV/0!",""))
training1     <-training[,colSums(is.na(training)) == 0]
testing <-read.csv('C:/Users/Vishn/Desktop/project ds/data/pml-testing.csv', na.strings=c("NA","#DIV/0!",""))
dim(training)
dim(testing)
Training   <-training1[,-c(1:7)]
Test   <-testing[,-c(1:7)]
Split <- createDataPartition(Training$classe, p=0.70, list=F)
trainFinal <- Training[Split, ]
testFinal <- Test[-Split, ]
model <- "modelFit.RData"
if (!file.exists(model)) {
# If not, set up the parallel clusters.
require(parallel)
require(doParallel)
cl <- makeCluster(detectCores() - 1)
registerDoParallel(cl)
fit <- train(trainFinal$classe ~ ., method = "rf", data = trainFinal)
save(fit, file = "modelFit.RData")
stopCluster(cl)
} else {
# Good model exists from previous run, load it and use it.
load(file = "modelFit.RData", verbose = TRUE)
}
library(caret)
library(randomForest)
library(foreach)
library(parallel)
library(doParallel)
training<-read.csv('C:/Users/Vishn/Desktop/project ds/data/pml-training.csv', na.strings=c("NA","#DIV/0!",""))
#training1     <-training[,colSums(is.na(training)) == 0]
testing <-read.csv('C:/Users/Vishn/Desktop/project ds/data/pml-testing.csv', na.strings=c("NA","#DIV/0!",""))
dim(training)
dim(testing)
#Training   <-training1[,-c(1:7)]
#Test   <-testing[,-c(1:7)]
subTrain <-
training[, names(training)[!(nzv(training, saveMetrics = T)[, 4])]]
# Remove columns with NA or is empty
subTrain <-
subTrain[, names(subTrain)[sapply(subTrain, function (x)
! (any(is.na(x) | x == "")))]]
# Remove V1 which seems to be a serial number, and
# cvtd_timestamp that is unlikely to influence the prediction
subTrain <- subTrain[,-1]
subTrain <- subTrain[, c(1:3, 5:58)]
Split <- createDataPartition(subTrain$classe, p=0.70, list=F)
trainFinal <- Training[Split, ]
testFinal <- Test[-Split, ]
model <- "modelFit.RData"
if (!file.exists(model)) {
# If not, set up the parallel clusters.
require(parallel)
require(doParallel)
cl <- makeCluster(detectCores() - 1)
registerDoParallel(cl)
fit <- train(trainFinal$classe ~ ., method = "rf", data = trainFinal)
save(fit, file = "modelFit.RData")
stopCluster(cl)
} else {
# Good model exists from previous run, load it and use it.
load(file = "modelFit.RData", verbose = TRUE)
}
Split <- createDataPartition(subTrain$classe, p=0.60, list=FALSE)
library(caret)
library(randomForest)
library(foreach)
library(parallel)
library(doParallel)
training<-read.csv('C:/Users/Vishn/Desktop/project ds/data/pml-training.csv', na.strings=c("NA","#DIV/0!",""))
#training1     <-training[,colSums(is.na(training)) == 0]
testing <-read.csv('C:/Users/Vishn/Desktop/project ds/data/pml-testing.csv', na.strings=c("NA","#DIV/0!",""))
dim(training)
dim(testing)
#Training   <-training1[,-c(1:7)]
#Test   <-testing[,-c(1:7)]
subTrain <-
training[, names(training)[!(nzv(training, saveMetrics = T)[, 4])]]
# Remove columns with NA or is empty
subTrain <-
subTrain[, names(subTrain)[sapply(subTrain, function (x)
! (any(is.na(x) | x == "")))]]
# Remove V1 which seems to be a serial number, and
# cvtd_timestamp that is unlikely to influence the prediction
subTrain <- subTrain[,-1]
subTrain <- subTrain[, c(1:3, 5:58)]
Split <- createDataPartition(subTrain$classe, p=0.60, list=FALSE)
trainFinal <- Training[Split, ]
testFinal <- Test[-Split, ]
classe<-trainFinal$classe
model <- "modelFit.RData"
if (!file.exists(model)) {
# If not, set up the parallel clusters.
require(parallel)
require(doParallel)
cl <- makeCluster(detectCores() - 1)
registerDoParallel(cl)
fit <- train(trainFinal$classe ~ ., method = "rf", data = trainFinal)
save(fit, file = "modelFit.RData")
stopCluster(cl)
} else {
# Good model exists from previous run, load it and use it.
load(file = "modelFit.RData", verbose = TRUE)
}
library(caret)
library(rpart)
library(rpart.plot)
library(randomForest)
library(corrplot)
install.packages("corrplot")
install.packages("rpart.plot")
library(caret)
library(rpart)
library(rpart.plot)
library(randomForest)
library(corrplot)
trainUrl <-"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
testUrl <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
trainFile <- "./data/pml-training.csv"
testFile  <- "./data/pml-testing.csv"
if (!file.exists("./data")) {
dir.create("./data")
}
if (!file.exists(trainFile)) {
download.file(trainUrl, destfile=trainFile, method="curl")
}
if (!file.exists(testFile)) {
download.file(testUrl, destfile=testFile, method="curl")
}
trainRaw <- read.csv("./data/pml-training.csv")
testRaw <- read.csv("./data/pml-testing.csv")
sum(complete.cases(trainRaw))
trainRaw <- trainRaw[, colSums(is.na(trainRaw)) == 0]
testRaw <- testRaw[, colSums(is.na(testRaw)) == 0]
trainRaw <- trainRaw[, colSums(is.na(trainRaw)) == 0]
testRaw <- testRaw[, colSums(is.na(testRaw)) == 0]
classe <- trainRaw$classe
trainRemove <- grepl("^X|timestamp|window", names(trainRaw))
trainRaw <- trainRaw[, !trainRemove]
trainCleaned <- trainRaw[, sapply(trainRaw, is.numeric)]
trainCleaned$classe <- classe
testRemove <- grepl("^X|timestamp|window", names(testRaw))
testRaw <- testRaw[, !testRemove]
testCleaned <- testRaw[, sapply(testRaw, is.numeric)]
trainData <- trainCleaned[inTrain, ]
testData <- trainCleaned[-inTrain, ]
inTrain <- createDataPartition(trainCleaned$classe, p=0.70, list=F)
trainData <- trainCleaned[inTrain, ]
testData <- trainCleaned[-inTrain, ]
fit <- train(classe ~ ., data=trainData, method="rf", trControl=controlRf, ntree=250)
save(fit, file = "modelFit.RData")
fit <- train(classe ~ ., data=trainData, method="rf", trControl=controlRf, ntree=250)
controlRf <- trainControl(method="cv", 5)
fit <- train(classe ~ ., data=trainData, method="rf", trControl=controlRf, ntree=250)
save(fit, file = "modelFit.RData")
predictRf <- predict(modelRf, testData)
confusionMatrix(testData$classe, predictRf)
predictRf <- predict(fit, testData)
confusionMatrix(testData$classe, predictRf)
library(caret)
library(rpart)
library(rpart.plot)
library(randomForest)
library(corrplot)
trainRaw <- read.csv('C:/Users/Vishn/Desktop/project ds/data/pml-training.csv', na.strings=c("NA","#DIV/0!",""))
testRaw <- read.csv('C:/Users/Vishn/Desktop/project ds/data/pml-testing.csv', na.strings=c("NA","#DIV/0!",""))
sum(complete.cases(trainRaw))
trainRaw <- trainRaw[, colSums(is.na(trainRaw)) == 0]
testRaw <- testRaw[, colSums(is.na(testRaw)) == 0]
classe <- trainRaw$classe
trainRemove <- grepl("^X|timestamp|window", names(trainRaw))
trainRaw <- trainRaw[, !trainRemove]
trainCleaned <- trainRaw[, sapply(trainRaw, is.numeric)]
trainCleaned$classe <- classe
testRemove <- grepl("^X|timestamp|window", names(testRaw))
testRaw <- testRaw[, !testRemove]
testCleaned <- testRaw[, sapply(testRaw, is.numeric)]
inTrain <- createDataPartition(trainCleaned$classe, p=0.70, list=F)
trainData <- trainCleaned[inTrain, ]
testData <- trainCleaned[-inTrain, ]
controlRf <- trainControl(method="cv", 5)
fit <- train(classe ~ ., data=trainData, method="rf", trControl=controlRf, ntree=250)
save(fit, file = "modelFit.RData")
predictRf <- predict(fit, testData)
confusionMatrix(testData$classe, predictRf)
library(foreach)
library(parallel)
library(doParallel)
library(caret)
library(rpart)
library(rpart.plot)
library(randomForest)
library(corrplot)
library(foreach)
library(parallel)
library(doParallel)
training <- read.csv('C:/Users/Vishn/Desktop/project ds/data/pml-training.csv', na.strings=c("NA","#DIV/0!",""))
testing <- read.csv('C:/Users/Vishn/Desktop/project ds/data/pml-testing.csv', na.strings=c("NA","#DIV/0!",""))
summary(training)
summary(testing)
training <- training[, colSums(is.na(training)) == 0]
testing <- testing[, colSums(is.na(testing)) == 0]
classe <- training$classe
traintmp <- grepl("^X|timestamp|window", names(training))
training <- training[, !traintmp]
trainFinal <- training[, sapply(training, is.numeric)]
trainFinal$classe <- classe
testtmp <- grepl("^X|timestamp|window", names(testing))
testing] <- testing[, !testtmp]
testFinal <- testing[, sapply(testing, is.numeric)]
Split <- createDataPartition(trainFinal$classe, p=0.70, list=FALSE)
trainData <- trainCleaned[Split, ]
testData <- trainCleaned[-Split, ]
fit <- train(classe ~ ., data=trainData, method="rf", trControl=trainControl(method="cv", 5), ntree=250)
save(fit, file = "modelFit.RData")
predictRf <- predict(fit, testData)
confusionMatrix(testData$classe, predictRf)
library(caret)
library(rpart)
library(rpart.plot)
library(randomForest)
library(corrplot)
library(foreach)
library(parallel)
library(doParallel)
training <- read.csv('C:/Users/Vishn/Desktop/project ds/data/pml-training.csv', na.strings=c("NA","#DIV/0!",""))
testing <- read.csv('C:/Users/Vishn/Desktop/project ds/data/pml-testing.csv', na.strings=c("NA","#DIV/0!",""))
summary(training)
summary(testing)
training <- training[, colSums(is.na(training)) == 0]
testing <- testing[, colSums(is.na(testing)) == 0]
classe <- training$classe
traintmp <- grepl("^X|timestamp|window", names(training))
training <- training[, !traintmp]
trainFinal <- training[, sapply(training, is.numeric)]
trainFinal$classe <- classe
testtmp <- grepl("^X|timestamp|window", names(testing))
testing <- testing[, !testtmp]
testFinal <- testing[, sapply(testing, is.numeric)]
Split <- createDataPartition(trainFinal$classe, p=0.70, list=FALSE)
trainData <- trainCleaned[Split, ]
testData <- trainCleaned[-Split, ]
fit <- train(classe ~ ., data=trainData, method="rf", trControl=trainControl(method="cv", 5), ntree=250)
save(fit, file = "modelFit.RData")
predictRf <- predict(fit, testData)
confusionMatrix(testData$classe, predictRf)
library(caret)
library(randomForest)
training <- read.csv('C:/Users/Vishn/Desktop/project ds/data/pml-training.csv', na.strings=c("NA","#DIV/0!",""))
testing <- read.csv('C:/Users/Vishn/Desktop/project ds/data/pml-testing.csv', na.strings=c("NA","#DIV/0!",""))
dim(training)
dim(testing)
summary(training)
summary(testing)
head(training)
redictTest <- predict(fit, testFinal)
predictTest <- predict(fit, testFinal)
predictTest
predictTest <- predict(fit, testData)
predictTest
predictTest <- predict(fit, testFinal)
predictTest <- predict(fit, testFinal)
predictTest
A={1,3,-1}
l=[]
p=[]
m=-2147483648
n=2147483648
for i in range(len(A))
l.append(A[i]+i)
p.append(A[i]-i)
print(max((max(l)-min(l))),(max(p)-min(p)))
reticulate::repl_python()
y
conda activate r-reticulate
A={1,3,-1}
l=[]
p=[]
m=-2147483648
n=2147483648
for i in range(len(A))
l.append(A[i]+i)
p.append(A[i]-i)
print(max((max(l)-min(l))),(max(p)-min(p)))
